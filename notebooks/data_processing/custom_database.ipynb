{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ogrdb json file \n",
    "# convert to fasta\n",
    "# translate to amino acids\n",
    "# align to existing genes database\n",
    "  \n",
    "\n",
    "# riot poc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import genes from OGRDB\n",
    "# j genes for light chains are shared between strains\n",
    "igkj_all = \"https://ogrdb.airr-community.org/download_germline_set/Mus%20musculus/IGKJ%20(all%20strains)/published/ungapped\"\n",
    "iglj_all = \"https://ogrdb.airr-community.org/download_germline_set/Mus%20musculus/IGLJ%20(all%20strains)/published/ungapped\"\n",
    "\n",
    "# C57BL/6(J)\n",
    "# IGH file contains sequences for V, D and J alleles\n",
    "# to split sequences by locus, import airr file\n",
    "igh_airr = \"https://ogrdb.airr-community.org/download_germline_set/Mus%20musculus/C57BL%25252f6/C57BL%25252f6%20IGH/published/airr\"\n",
    "igkv = \"https://ogrdb.airr-community.org/download_germline_set/Mus%20musculus/C57BL%25252f6J/C57BL%25252f6J%20IGKV/published/ungapped\"\n",
    "iglv = \"https://ogrdb.airr-community.org/download_germline_set/Mus%20musculus/C57BL%25252f6J/C57BL%25252f6J%20IGLV/published/ungapped\"\n",
    "\n",
    "# c_genes =\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "data_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/raw/\"\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# download files\n",
    "def download_file(url, path):\n",
    "    r = requests.get(url)\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "download_file(igkj_all, data_path + \"igkj.fasta\")\n",
    "download_file(iglj_all, data_path + \"iglj.fasta\")\n",
    "\n",
    "download_file(igh_airr, data_path + \"igh_airr.json\")\n",
    "download_file(igkv, data_path + \"igkv.fasta\")\n",
    "download_file(iglv, data_path + \"iglv.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we want to split the sequences \n",
    "# gene_db/v_genes/organism.fasta\n",
    "# gene_db/d_genes/organism/igh.fasta\n",
    "# gene_db/j_genes/organism/igh.fasta\n",
    "# gene_db/j_genes/organism/igk.fasta\n",
    "# gene_db/j_genes/organism/igl.fasta\n",
    "\n",
    "# first we copy V genes\n",
    "# v gene header has the following format: >{allele_name}    {locus} {reading_frame} {species}\n",
    "# we need to specify organism as custom\n",
    "# reading frame is always 0 in this case\n",
    "# >IGHV4-28*07\tIGH\t0\tHOMO_SAPIENS\n",
    "\n",
    "# IGHV alleles\n",
    "# read file to dict (one big nested json)\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "\n",
    "igh_data = {}\n",
    "with open(data_path + \"igh_airr.json\", 'r') as f:\n",
    "    igh_data = json.load(f)\n",
    "\n",
    "database_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/\"\n",
    "v_genes_path = os.path.join(database_path, \"v_genes\")\n",
    "os.makedirs(v_genes_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(v_genes_path, \"custom.fasta\"), \"w\") as v_genes_file:\n",
    "    for allele_data in igh_data[\"GermlineSet\"][0][\"allele_descriptions\"]:\n",
    "        name = allele_data[\"label\"]\n",
    "        sequence = allele_data[\"coding_sequence\"]\n",
    "        sequence_type = allele_data[\"sequence_type\"]\n",
    "\n",
    "        if sequence_type == \"V\":\n",
    "            v_genes_file.write(f\">{name}\\tIGH\\t0\\tCUSTOM\\n{sequence}\\n\")\n",
    "\n",
    "\n",
    "    # IGKV and IGLV should be just rewritten\n",
    "    igkv_records = SeqIO.parse(data_path + \"igkv.fasta\", \"fasta\")\n",
    "    for record in igkv_records:\n",
    "        v_genes_file.write(f\">{record.id}\\tIGK\\t0\\tCUSTOM\\n{record.seq}\\n\")\n",
    "\n",
    "    iglv_records = SeqIO.parse(data_path + \"iglv.fasta\", \"fasta\")\n",
    "    for record in iglv_records:\n",
    "        v_genes_file.write(f\">{record.id}\\tIGL\\t0\\tCUSTOM\\n{record.seq}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "\n",
    "igh_data = {}\n",
    "data_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/raw/\"\n",
    "\n",
    "\n",
    "with open(data_path + \"igh_airr.json\", 'r') as f:\n",
    "    igh_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def translate(query_sequence: str, coding_frame: int) -> str:\n",
    "    assert coding_frame in [0, 1, 2]\n",
    "\n",
    "    query_sequence = query_sequence[coding_frame:]\n",
    "    partial_codon_len = len(query_sequence) % 3\n",
    "    if partial_codon_len:\n",
    "        query_sequence = query_sequence[:-partial_codon_len]  # To avoid BioPython \"Partial codon\" warning.\n",
    "    coding_dna = Seq(query_sequence)\n",
    "    return str(coding_dna.translate(gap=\".\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "aa_database_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/aa_genes\"\n",
    "aa_v_genes_path = os.path.join(aa_database_path, \"v_genes\")\n",
    "os.makedirs(aa_v_genes_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(aa_v_genes_path, \"custom.fasta\"), \"w\") as v_genes_file:\n",
    "    for allele_data in igh_data[\"GermlineSet\"][0][\"allele_descriptions\"]:\n",
    "        name = allele_data[\"label\"]\n",
    "        sequence = allele_data[\"coding_sequence\"]\n",
    "        translated_sequence = translate(sequence, 0)\n",
    "        sequence_type = allele_data[\"sequence_type\"]\n",
    "\n",
    "        if sequence_type == \"V\":\n",
    "            v_genes_file.write(f\">{name}\\tIGH\\tCUSTOM\\n{translated_sequence}\\n\")\n",
    "\n",
    "\n",
    "    # IGKV and IGLV should be just rewritten\n",
    "    igkv_records = SeqIO.parse(data_path + \"igkv.fasta\", \"fasta\")\n",
    "    for record in igkv_records:\n",
    "        translated_sequence = translate(str(record.seq), 0)\n",
    "        v_genes_file.write(f\">{record.id}\\tIGK\\tCUSTOM\\n{translated_sequence}\\n\")\n",
    "\n",
    "    iglv_records = SeqIO.parse(data_path + \"iglv.fasta\", \"fasta\")\n",
    "    for record in iglv_records:\n",
    "        translated_sequence = translate(str(record.seq), 0)\n",
    "        v_genes_file.write(f\">{record.id}\\tIGL\\tCUSTOM\\n{translated_sequence}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer scheme mappings for v genes\n",
    "# lets start with alignment of aa sequence to the existing database\n",
    "\n",
    "from riot_na.data.model import Organism\n",
    "from riot_na.config import GENE_DB_DIR\n",
    "\n",
    "from riot_na.alignment.gene_aligner import create_aa_v_gene_aligner\n",
    "\n",
    "\n",
    "allowed_species = [Organism.HOMO_SAPIENS, Organism.MUS_MUSCULUS]\n",
    "\n",
    "aa_genes_dir = GENE_DB_DIR / \"gene_db\" / \"aa_genes_deduplicated\"\n",
    "v_aligner = create_aa_v_gene_aligner(allowed_species=allowed_species, aa_genes_dir=aa_genes_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlignmentEntryAA(target_id='IGHV-4TP6', alignment_score=207.94997184789176, seq_identity=1.0, e_value=4.334877459455786e-154, q_start=0, q_end=100, t_start=0, t_end=100, cigar='100M', species=<Organism.MUS_MUSCULUS: 'mouse'>, locus=<Locus.IGH: 'igh'>, q_seq='QVTLKESGPGILQPSQTLSLTCSFSGFSLSTSNMGIGWIRQPSGKGLEWLAHIWWNDDKYYNPSLKSRLTISKDTSNNQVFLKITSVDTADTATYYCAQI', t_seq='QVTLKESGPGILQPSQTLSLTCSFSGFSLSTSNMGIGWIRQPSGKGLEWLAHIWWNDDKYYNPSLKSRLTISKDTSNNQVFLKITSVDTADTATYYCAQI')\n"
     ]
    }
   ],
   "source": [
    "sample_v_gene_aa = \"QVTLKESGPGILQPSQTLSLTCSFSGFSLSTSNMGIGWIRQPSGKGLEWLAHIWWNDDKYYNPSLKSRLTISKDTSNNQVFLKITSVDTADTATYYCAQI\"\n",
    "v_aln = v_aligner.align(sample_v_gene_aa)\n",
    "print(v_aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMMMMMMMMDMMMMMMMMMMMMMMMMMMMMMDDMMMMMMMMMMMMMMMMMMMMMMMMMMDDDMMMMMMMMMMDMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from riot_na.data.scheme_mapping_facade import SchemeMappingFacade\n",
    "from riot_na.data.model import Scheme\n",
    "\n",
    "v_scheme_mapping_facade = SchemeMappingFacade(Scheme.IMGT, allowed_species, GENE_DB_DIR)\n",
    "v_target_scheme_mapping = v_scheme_mapping_facade.get_mapping(v_aln.species, v_aln.target_id)\n",
    "v_target_scheme_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge alignments\n",
    "from riot_na.alignment.alignment_utils import unfold_cigar\n",
    "from riot_na.schemes.scheme_alignment import force_n_terminus_matches, force_c_terminus_matches\n",
    "from riot_na.schemes.collapse_alignment import collapse_alignment_str\n",
    "from riot_na.schemes.scheme_alignment import force_n_terminus_del_ins\n",
    "\n",
    "from riot_na.schemes.scheme_alignment import _merge_cigars\n",
    "\n",
    "\n",
    "fixed_v_aln = force_n_terminus_matches(v_aln)\n",
    "\n",
    "v_query_gene_alignment_str = unfold_cigar(fixed_v_aln.cigar)\n",
    "v_query_gene_alignment_str = collapse_alignment_str(v_query_gene_alignment_str)\n",
    "v_query_gene_alignment_str = force_n_terminus_del_ins(fixed_v_aln, v_query_gene_alignment_str)\n",
    "\n",
    "v_query_scheme_alignment_str = _merge_cigars(v_query_gene_alignment_str, v_target_scheme_mapping)\n",
    "v_query_scheme_alignment_str\n",
    "\n",
    "# verify the alignment spans the whole query sequence, otherwise raise an exception\n",
    "assert v_query_scheme_alignment_str.count(\"M\") + v_query_scheme_alignment_str.count(\"I\") == len(sample_v_gene_aa), \"Inferred alignment does not span the whole query sequence\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_v_gene_scheme_mapping(aa_sequence, scheme: Scheme):\n",
    "    allowed_species = [Organism.HOMO_SAPIENS, Organism.MUS_MUSCULUS]\n",
    "\n",
    "    aa_genes_dir = GENE_DB_DIR / \"gene_db\" / \"aa_genes_deduplicated\"\n",
    "    v_aligner = create_aa_v_gene_aligner(allowed_species=allowed_species, aa_genes_dir=aa_genes_dir)\n",
    "\n",
    "    prefiltering_result = v_aligner._prefilter(aa_sequence)\n",
    "    alignments = v_aligner._align_sequences(aa_sequence, prefiltering_result)\n",
    "\n",
    "    if not alignments:\n",
    "        print(f\"Could not align sequence: {aa_sequence}\")\n",
    "        print(f\"Could not find any alignments\")\n",
    "        return None\n",
    "\n",
    "    # in this case we want to find the longest alignment\n",
    "    # therefore we should sort the alignments by the length of the alignment (DESC), then e-value (ASC)\n",
    "    # find longest alignment: \n",
    "\n",
    "    v_aln = None\n",
    "    longest_aln = None\n",
    "\n",
    "    for aln in alignments:\n",
    "        fixed_aln = force_n_terminus_matches(aln)\n",
    "        fixed_aln = force_c_terminus_matches(aa_sequence, aln.t_seq, fixed_aln)\n",
    "\n",
    "        aln_len = fixed_aln.q_end - fixed_aln.q_start\n",
    "        if longest_aln is None or aln_len > longest_aln:\n",
    "            longest_aln = aln_len\n",
    "            v_aln = aln\n",
    "        elif longest_aln is None or aln_len > longest_aln:\n",
    "            if v_aln is None or aln.e_value < v_aln.e_value:\n",
    "                v_aln = aln\n",
    "                \n",
    "    if longest_aln < len(aa_sequence):\n",
    "        print(f\"Could not align sequence: {aa_sequence}\")\n",
    "        print(\"Could not find alignment covering query sequence\")\n",
    "\n",
    "   \n",
    "    v_scheme_mapping_facade = SchemeMappingFacade(scheme, allowed_species, GENE_DB_DIR)\n",
    "    v_target_scheme_mapping = v_scheme_mapping_facade.get_mapping(v_aln.species, v_aln.target_id)\n",
    "\n",
    "    fixed_aln = force_n_terminus_matches(v_aln)\n",
    "    fixed_aln = force_c_terminus_matches(aa_sequence, v_aln.t_seq, fixed_aln)\n",
    "\n",
    "    v_query_gene_alignment_str = unfold_cigar(fixed_aln.cigar)\n",
    "    v_query_gene_alignment_str = collapse_alignment_str(v_query_gene_alignment_str)\n",
    "    v_query_gene_alignment_str = force_n_terminus_del_ins(fixed_aln, v_query_gene_alignment_str)\n",
    "    v_query_scheme_alignment_str = _merge_cigars(v_query_gene_alignment_str, v_target_scheme_mapping)\n",
    "\n",
    "    # verify the alignment spans the whole query sequence, otherwise raise an exception\n",
    "    # assert v_query_scheme_alignment_str.count(\"M\") + v_query_scheme_alignment_str.count(\"I\") == len(aa_sequence), \"Inferred alignment does not span the whole query sequence\"\n",
    "\n",
    "    return v_query_scheme_alignment_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scheme: kabat\n",
      "Could not align sequence: EVQLQQSGPELVKPGDSVKISCKASGYSFTGYFMNWVMXEPWKEP*VDWTY*SLQW*YFLQPEVQGQGHIDCRQIL*HSPHGAPEPDI*GLCSLLLCK\n",
      "Could not find any alignments\n",
      "Could not align sequence: QLVLTQSSSASFSLGASAKLTCTLSSQHSTYTIEWYQQQPLKPPKYVMELKKDGSHSTGDGIPDRFSGSSSGADRYLSISNIQPEDEAIYICGVGDTIKEQFV*\n",
      "Could not find alignment covering query sequence\n",
      "Processing scheme: chothia\n",
      "Could not align sequence: EVQLQQSGPELVKPGDSVKISCKASGYSFTGYFMNWVMXEPWKEP*VDWTY*SLQW*YFLQPEVQGQGHIDCRQIL*HSPHGAPEPDI*GLCSLLLCK\n",
      "Could not find any alignments\n",
      "Could not align sequence: QLVLTQSSSASFSLGASAKLTCTLSSQHSTYTIEWYQQQPLKPPKYVMELKKDGSHSTGDGIPDRFSGSSSGADRYLSISNIQPEDEAIYICGVGDTIKEQFV*\n",
      "Could not find alignment covering query sequence\n",
      "Processing scheme: imgt\n",
      "Could not align sequence: EVQLQQSGPELVKPGDSVKISCKASGYSFTGYFMNWVMXEPWKEP*VDWTY*SLQW*YFLQPEVQGQGHIDCRQIL*HSPHGAPEPDI*GLCSLLLCK\n",
      "Could not find any alignments\n",
      "Could not align sequence: QLVLTQSSSASFSLGASAKLTCTLSSQHSTYTIEWYQQQPLKPPKYVMELKKDGSHSTGDGIPDRFSGSSSGADRYLSISNIQPEDEAIYICGVGDTIKEQFV*\n",
      "Could not find alignment covering query sequence\n",
      "Processing scheme: martin\n",
      "Could not align sequence: EVQLQQSGPELVKPGDSVKISCKASGYSFTGYFMNWVMXEPWKEP*VDWTY*SLQW*YFLQPEVQGQGHIDCRQIL*HSPHGAPEPDI*GLCSLLLCK\n",
      "Could not find any alignments\n",
      "Could not align sequence: QLVLTQSSSASFSLGASAKLTCTLSSQHSTYTIEWYQQQPLKPPKYVMELKKDGSHSTGDGIPDRFSGSSSGADRYLSISNIQPEDEAIYICGVGDTIKEQFV*\n",
      "Could not find alignment covering query sequence\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "aa_database_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/aa_genes\"\n",
    "aa_v_genes_path = os.path.join(aa_database_path, \"v_genes\")\n",
    "\n",
    "v_gene_aa_file = os.path.join(aa_v_genes_path, \"custom.fasta\")\n",
    "\n",
    "\n",
    "for scheme in Scheme:\n",
    "\n",
    "    print(f\"Processing scheme: {scheme.value}\")\n",
    "    scheme_mapping_path = f\"/home/pawel/workspace/riot_na/notebooks/data_processing/data/scheme_mappings/custom/{scheme.value}/\"\n",
    "    os.makedirs(scheme_mapping_path, exist_ok=True)\n",
    "\n",
    "    scheme_mapping_file = f\"/home/pawel/workspace/riot_na/notebooks/data_processing/data/scheme_mappings/custom/{scheme.value}/scheme_mapping.csv\"\n",
    "\n",
    "    # write csv header gene_id,scheme_cigar\n",
    "    with open(scheme_mapping_file, \"w\") as scheme_mapping_file:\n",
    "        scheme_mapping_file.write(\"gene_id,scheme_cigar\\n\")\n",
    "        \n",
    "        v_gene_aa_records = SeqIO.parse(v_gene_aa_file, \"fasta\")\n",
    "\n",
    "        for record in v_gene_aa_records:\n",
    "            aa_sequence = str(record.seq)\n",
    "            v_query_scheme_alignment_str = infer_v_gene_scheme_mapping(aa_sequence, scheme)\n",
    "\n",
    "            if v_query_scheme_alignment_str is not None:\n",
    "                scheme_mapping_file.write(f\"{record.id},{v_query_scheme_alignment_str}\\n\")\n",
    "\n",
    "        # save to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not align sequence: QLVLTQSSSASFSLGASAKLTCTLSSQHSTYTIEWYQQQPLKPPKYVMELKKDGSHSTGDGIPDRFSGSSSGADRYLSISNIQPEDEAIYICGVGDTIKEQFV*\n",
      "Could not find alignment covering query sequence\n"
     ]
    }
   ],
   "source": [
    "# infer_v_gene_scheme_mapping(\"*VQLQQSGPELVKPGASVKMSCKASGYTFTDYYMHWVKQKPGKGLEWIGEIYPGSGNTYYNEKFKGKATLTADTSSSTAYMQLSSLTSEDSAVYFCAR\", Scheme.IMGT)\n",
    "# infer_v_gene_scheme_mapping(\"*VQLQQSGPELVKPGASVKMSCKASGYTFTDYYMHWVKQKPGKGLEWIGEIYPGSGNTYYNEKFKGKATLTADTSSSTAYMQLSSLTSEDSAVYFCAR\", Scheme.IMGT)\n",
    "infer_v_gene_scheme_mapping(\"QLVLTQSSSASFSLGASAKLTCTLSSQHSTYTIEWYQQQPLKPPKYVMELKKDGSHSTGDGIPDRFSGSSSGADRYLSISNIQPEDEAIYICGVGDTIKEQFV*\", Scheme.IMGT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D genes should be just rewritten\n",
    "database_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/\"\n",
    "d_genes_path = os.path.join(database_path, \"d_genes\", \"custom\")\n",
    "\n",
    "os.makedirs(d_genes_path, exist_ok=True)\n",
    "with open(os.path.join(d_genes_path, \"igh.fasta\"), \"w\") as v_genes_file:\n",
    "    for allele_data in igh_data[\"GermlineSet\"][0][\"allele_descriptions\"]:\n",
    "        name = allele_data[\"label\"]\n",
    "        sequence = allele_data[\"coding_sequence\"]\n",
    "        sequence_type = allele_data[\"sequence_type\"]\n",
    "\n",
    "        if sequence_type == \"D\":\n",
    "            # nt d alleles: >IGHD2-2*02\tHOMO_SAPIENS\n",
    "            v_genes_file.write(f\">{name}\\tCUSTOM\\n{sequence}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J genes\n",
    "\n",
    "from riot_na.data.model import Locus\n",
    "from riot_na.alignment.gene_aligner import create_aligner\n",
    "from riot_na.data.model import GermlineGene\n",
    "from riot_na.alignment.alignment_utils import infer_reading_frame\n",
    "\n",
    "\n",
    "igh_data = {}\n",
    "with open(data_path + \"igh_airr.json\", 'r') as f:\n",
    "    igh_data = json.load(f)\n",
    "\n",
    "database_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/\"\n",
    "j_genes_path = os.path.join(database_path, \"j_genes\")\n",
    "os.makedirs(j_genes_path, exist_ok=True)\n",
    "\n",
    "j_genes_aa_path = os.path.join(database_path, \"aa_genes\", \"j_genes\", \"custom\")\n",
    "os.makedirs(j_genes_aa_path, exist_ok=True)\n",
    "\n",
    "\n",
    "ighj_human_aligner = create_aligner(Organism.HOMO_SAPIENS, germline_gene=GermlineGene.J, locus=Locus.IGH)\n",
    "ighj_mouse_aligner = create_aligner(Organism.MUS_MUSCULUS, germline_gene=GermlineGene.J, locus=Locus.IGH)\n",
    "\n",
    "with open(os.path.join(j_genes_path, \"custom.fasta\"), \"w\") as j_genes_file, open(os.path.join(j_genes_aa_path, \"igh.fasta\"), \"w\") as j_genes_aa_file:\n",
    "    for allele_data in igh_data[\"GermlineSet\"][0][\"allele_descriptions\"]:\n",
    "        name = allele_data[\"label\"]\n",
    "        sequence = allele_data[\"coding_sequence\"]\n",
    "        sequence_type = allele_data[\"sequence_type\"]        \n",
    "\n",
    "        if sequence_type == \"J\":\n",
    "            # align sequence to known j genes of the same locus to infer reading frame\n",
    "\n",
    "            human_prefiltering_result = ighj_human_aligner._prefilter(sequence, False)\n",
    "            human_alignments = ighj_human_aligner._align_sequences(sequence, human_prefiltering_result)\n",
    "\n",
    "            mouse_prefiltering_result = ighj_mouse_aligner._prefilter(sequence, False)\n",
    "            mouse_alignments = ighj_mouse_aligner._align_sequences(sequence, mouse_prefiltering_result)\n",
    "\n",
    "            all_alignments = []\n",
    "\n",
    "            if human_alignments:\n",
    "                all_alignments.extend(human_alignments)\n",
    "            \n",
    "            if mouse_alignments:\n",
    "                all_alignments.extend(mouse_alignments)\n",
    "\n",
    "            if not all_alignments:\n",
    "                print(f\"Could not align sequence: {sequence}\")\n",
    "                print(\"Could not find any alignments\")\n",
    "                continue\n",
    "\n",
    "            # get the best alignment\n",
    "            all_alignments.sort()\n",
    "            best_alignment = all_alignments[0]\n",
    "\n",
    "            reading_frame = infer_reading_frame(best_alignment.t_start, best_alignment.reading_frame)\n",
    "            j_genes_file.write(f\">{name}\\tIGH\\t{reading_frame}\\tCUSTOM\\n{sequence}\\n\")\n",
    "\n",
    "            translated_sequence = translate(sequence, reading_frame)\n",
    "            j_genes_aa_file.write(f\">{name}\\tIGH\\tCUSTOM\\n{translated_sequence}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IGKV and IGLV should be just rewritten\n",
    "\n",
    "igkj_human_aligner = create_aligner(Organism.HOMO_SAPIENS, germline_gene=GermlineGene.J, locus=Locus.IGK)\n",
    "igkj_mouse_aligner = create_aligner(Organism.MUS_MUSCULUS, germline_gene=GermlineGene.J, locus=Locus.IGK)\n",
    "\n",
    "igkj_records = SeqIO.parse(data_path + \"igkj.fasta\", \"fasta\")\n",
    "with open(os.path.join(j_genes_path, \"custom.fasta\"), \"a\") as j_genes_file, open(os.path.join(j_genes_aa_path, \"igk.fasta\"), \"w\") as j_genes_aa_file:\n",
    "\n",
    "    for record in igkj_records:\n",
    "\n",
    "        name = record.id\n",
    "        sequence = str(record.seq)\n",
    "\n",
    "        human_prefiltering_result = igkj_human_aligner._prefilter(sequence, False)\n",
    "        human_alignments = igkj_human_aligner._align_sequences(sequence, human_prefiltering_result)\n",
    "\n",
    "        mouse_prefiltering_result = igkj_mouse_aligner._prefilter(sequence, False)\n",
    "        mouse_alignments = igkj_mouse_aligner._align_sequences(sequence, mouse_prefiltering_result)\n",
    "\n",
    "        all_alignments = []\n",
    "\n",
    "        if human_alignments:\n",
    "            all_alignments.extend(human_alignments)\n",
    "        \n",
    "        if mouse_alignments:\n",
    "            all_alignments.extend(mouse_alignments)\n",
    "\n",
    "        if not all_alignments:\n",
    "            print(f\"Could not align sequence: {sequence}\")\n",
    "            print(\"Could not find any alignments\")\n",
    "            continue\n",
    "\n",
    "        # get the best alignment\n",
    "        all_alignments.sort()\n",
    "        best_alignment = all_alignments[0]\n",
    "\n",
    "        reading_frame = infer_reading_frame(best_alignment.t_start, best_alignment.reading_frame) \n",
    "        j_genes_file.write(f\">{record.id}\\tIGK\\t{reading_frame}\\tCUSTOM\\n{record.seq}\\n\")\n",
    "\n",
    "        translated_sequence = translate(sequence, reading_frame)\n",
    "        j_genes_aa_file.write(f\">{name}\\tIGK\\tCUSTOM\\n{translated_sequence}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iglj_human_aligner = create_aligner(Organism.HOMO_SAPIENS, germline_gene=GermlineGene.J, locus=Locus.IGL)\n",
    "iglj_mouse_aligner = create_aligner(Organism.MUS_MUSCULUS, germline_gene=GermlineGene.J, locus=Locus.IGL)\n",
    "\n",
    "iglj_records = SeqIO.parse(data_path + \"iglj.fasta\", \"fasta\")\n",
    "\n",
    "\n",
    "with open(os.path.join(j_genes_path, \"custom.fasta\"), \"a\") as j_genes_file, open(os.path.join(j_genes_aa_path, \"igl.fasta\"), \"w\") as j_genes_aa_file:\n",
    "\n",
    "    for record in iglj_records:\n",
    "\n",
    "        name = record.id\n",
    "        sequence = str(record.seq)\n",
    "\n",
    "        human_prefiltering_result = iglj_human_aligner._prefilter(sequence, False)\n",
    "        human_alignments = iglj_human_aligner._align_sequences(sequence, human_prefiltering_result)\n",
    "\n",
    "        mouse_prefiltering_result = iglj_mouse_aligner._prefilter(sequence, False)\n",
    "        mouse_alignments = iglj_mouse_aligner._align_sequences(sequence, mouse_prefiltering_result)\n",
    "\n",
    "        all_alignments = []\n",
    "\n",
    "        if human_alignments:\n",
    "            all_alignments.extend(human_alignments)\n",
    "        \n",
    "        if mouse_alignments:\n",
    "            all_alignments.extend(mouse_alignments)\n",
    "\n",
    "        if not all_alignments:\n",
    "            print(f\"Could not align sequence: {sequence}\")\n",
    "            print(\"Could not find any alignments\")\n",
    "            continue\n",
    "\n",
    "        # get the best alignment\n",
    "        all_alignments.sort()\n",
    "        best_alignment = all_alignments[0]\n",
    "\n",
    "        reading_frame = infer_reading_frame(best_alignment.t_start, best_alignment.reading_frame)\n",
    "        j_genes_file.write(f\">{record.id}\\tIGL\\t{reading_frame}\\tCUSTOM\\n{record.seq}\\n\")\n",
    "\n",
    "        translated_sequence = translate(sequence, reading_frame)\n",
    "        j_genes_aa_file.write(f\">{name}\\tIGL\\tCUSTOM\\n{translated_sequence}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from riot_na.alignment.aa_gene_alignments import create_aa_j_gene_aligner\n",
    "from riot_na.alignment.gene_aligner import GeneAlignerAA\n",
    "from riot_na.data.model import AlignmentEntryAA\n",
    "\n",
    "\n",
    "def infer_j_gene_scheme_mapping(aa_sequence, locus: Locus, scheme: Scheme):\n",
    "    allowed_species = [Organism.HOMO_SAPIENS, Organism.MUS_MUSCULUS]\n",
    "    aa_genes_dir = GENE_DB_DIR / \"gene_db\" / \"aa_genes_deduplicated\"\n",
    "\n",
    "    j_aligners: dict[Organism, GeneAlignerAA] = {}\n",
    "\n",
    "    for organism in allowed_species:\n",
    "        j_aligner = create_aa_j_gene_aligner(organism=organism, locus=locus, aa_genes_dir=aa_genes_dir)\n",
    "        j_aligners[organism] = j_aligner\n",
    "\n",
    "\n",
    "    all_alignments = []\n",
    "\n",
    "    for organism in allowed_species:\n",
    "        j_aligner = j_aligners[organism]\n",
    "        prefiltering_result = j_aligner._prefilter(aa_sequence)\n",
    "        alignments = j_aligner._align_sequences(aa_sequence, prefiltering_result)\n",
    "\n",
    "        if alignments:\n",
    "            all_alignments.extend(alignments)\n",
    "\n",
    "\n",
    "    if not all_alignments:\n",
    "        print(f\"Could not align sequence: {aa_sequence}\")\n",
    "        print(f\"Could not find any alignments\")\n",
    "        return None\n",
    "\n",
    "    # in this case we want to find the longest alignment\n",
    "    # therefore we should sort the alignments by the length of the alignment (DESC), then e-value (ASC)\n",
    "    # find longest alignment: \n",
    "\n",
    "    j_aln: AlignmentEntryAA = None\n",
    "    longest_aln = None\n",
    "\n",
    "    for aln in all_alignments:\n",
    "        fixed_aln = force_n_terminus_matches(aln)\n",
    "        fixed_aln = force_c_terminus_matches(aa_sequence, aln.t_seq, fixed_aln)\n",
    "\n",
    "        aln_len = fixed_aln.q_end - fixed_aln.q_start\n",
    "        if longest_aln is None or aln_len > longest_aln:\n",
    "            longest_aln = aln_len\n",
    "            j_aln = aln\n",
    "        elif longest_aln is None or aln_len > longest_aln:\n",
    "            if j_aln is None or aln.e_value < j_aln.e_value:\n",
    "                j_aln = aln\n",
    "                \n",
    "    if longest_aln < len(aa_sequence):\n",
    "        print(f\"Could not align sequence: {aa_sequence}\")\n",
    "        print(\"Could not find alignment covering query sequence\")\n",
    "\n",
    "   \n",
    "    j_scheme_mapping_facade = SchemeMappingFacade(scheme, allowed_species, GENE_DB_DIR)\n",
    "    j_target_scheme_mapping = j_scheme_mapping_facade.get_mapping(j_aln.species, j_aln.target_id)\n",
    "\n",
    "    fixed_aln = force_n_terminus_matches(j_aln)\n",
    "    fixed_aln = force_c_terminus_matches(aa_sequence, j_aln.t_seq, fixed_aln)\n",
    "\n",
    "    j_query_gene_alignment_str = unfold_cigar(fixed_aln.cigar)\n",
    "    j_query_gene_alignment_str = collapse_alignment_str(j_query_gene_alignment_str)\n",
    "    j_query_gene_alignment_str = force_n_terminus_del_ins(fixed_aln, j_query_gene_alignment_str)\n",
    "    j_query_scheme_alignment_str = _merge_cigars(j_query_gene_alignment_str, j_target_scheme_mapping)\n",
    "\n",
    "    return j_query_scheme_alignment_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMMMMMMMMMMM'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_j_gene_scheme_mapping(\"RFFFLKWPIVCR\", Locus.IGL, Scheme.IMGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/aa_genes/j_genes/custom'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_genes_aa_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scheme: kabat igh\n",
      "Processing scheme: kabat igl\n",
      "Processing scheme: kabat igk\n",
      "Processing scheme: chothia igh\n",
      "Processing scheme: chothia igl\n",
      "Processing scheme: chothia igk\n",
      "Processing scheme: imgt igh\n",
      "Processing scheme: imgt igl\n",
      "Processing scheme: imgt igk\n",
      "Processing scheme: martin igh\n",
      "Processing scheme: martin igl\n",
      "Processing scheme: martin igk\n"
     ]
    }
   ],
   "source": [
    "# prepare scheme mappings for j genes\n",
    "\n",
    "for scheme in Scheme:\n",
    "    for locus in Locus:\n",
    "\n",
    "        print(f\"Processing scheme: {scheme.value} {locus.value}\")\n",
    "        scheme_mapping_path = f\"/home/pawel/workspace/riot_na/notebooks/data_processing/data/scheme_mappings/custom/{scheme.value}/\"\n",
    "        os.makedirs(scheme_mapping_path, exist_ok=True)\n",
    "\n",
    "        scheme_mapping_file = f\"/home/pawel/workspace/riot_na/notebooks/data_processing/data/scheme_mappings/custom/{scheme.value}/scheme_mapping.csv\"\n",
    "\n",
    "        # write csv header gene_id,scheme_cigar\n",
    "        # scheme mappings are shared - do not create new file and write header \n",
    "        with open(scheme_mapping_file, \"a\") as scheme_mapping_file:\n",
    "\n",
    "            j_genes_aa_path\n",
    "            j_gene_aa_records = SeqIO.parse(os.path.join(j_genes_aa_path, f\"{locus.value}.fasta\"), \"fasta\")\n",
    "\n",
    "            for record in j_gene_aa_records:\n",
    "                aa_sequence = str(record.seq)\n",
    "                j_query_scheme_alignment_str = infer_j_gene_scheme_mapping(aa_sequence, locus, scheme)\n",
    "\n",
    "                if j_query_scheme_alignment_str is not None:\n",
    "                    scheme_mapping_file.write(f\"{record.id},{j_query_scheme_alignment_str}\\n\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"Could not infer scheme mapping for gene: {record.id}\")\n",
    "\n",
    "                # save to file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy c genes for nt alignments from riot\n",
    "c_genes_path = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/c_genes/\"\n",
    "\n",
    "os.makedirs(c_genes_path, exist_ok=True)\n",
    "\n",
    "download_file(\"https://github.com/NaturalAntibody/riot_na/blob/master/riot_na/databases/gene_db/c_genes/human/igh.fasta\", c_genes_path + \"igh.fasta\")\n",
    "download_file(\"https://github.com/NaturalAntibody/riot_na/blob/master/riot_na/databases/gene_db/c_genes/human/igk.fasta\", c_genes_path + \"igk.fasta\")\n",
    "download_file(\"https://github.com/NaturalAntibody/riot_na/blob/master/riot_na/databases/gene_db/c_genes/human/igl.fasta\", c_genes_path + \"igl.fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from riot_na.config import GENE_DB_DIR\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def df_to_fasta(df: pd.DataFrame, output_path: Path):\n",
    "    with output_path.open(\"w\") as output_file:\n",
    "        for row in df.itertuples(index=False):\n",
    "            output_file.write(f\">{row.description}\\n\")\n",
    "            output_file.write(f\"{row.sequence}\\n\")\n",
    "\n",
    "\n",
    "def deduplicate_genes(input_path) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = pd.DataFrame.from_records(\n",
    "        (\n",
    "            {\"allele_id\": record.id, \"description\": record.description, \"sequence\": str(record.seq)}\n",
    "            for record in SeqIO.parse(input_path, \"fasta\")\n",
    "        )\n",
    "    )\n",
    "    df[\"allele\"] = df[\"allele_id\"].str.split(\"*\").str[1]\n",
    "    df[\"gene_id\"] = df[\"allele_id\"].str.split(\"*\").str[0]\n",
    "\n",
    "    df = df.sort_values([\"gene_id\", \"allele\"])\n",
    "    deduplicated_df = df.drop_duplicates(subset=[\"sequence\"])\n",
    "    first_allele_df = deduplicated_df.groupby(\"gene_id\").first()\n",
    "    return deduplicated_df, first_allele_df\n",
    "\n",
    "\n",
    "AA_GENES_DIR = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/aa_genes\"\n",
    "OUTPUT_GENES_DEDUP_DIR = \"/home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/aa_genes_deduplicated\"\n",
    "\n",
    "input_path = Path(AA_GENES_DIR) /\"v_genes\"/ \"custom.fasta\"\n",
    "\n",
    "deduplicated_df, first_allele_df = deduplicate_genes(input_path)\n",
    "output_dir = Path(OUTPUT_GENES_DEDUP_DIR) / \"v_genes\"\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "df_to_fasta(deduplicated_df, output_dir / f\"custom.fasta\")\n",
    "\n",
    "for input_path in (Path(AA_GENES_DIR) / \"j_genes\" / \"custom\").iterdir():\n",
    "\n",
    "    deduplicated_df, first_allele_df = deduplicate_genes(input_path)\n",
    "    output_dir = Path(OUTPUT_GENES_DEDUP_DIR) / \"j_genes\" / \"custom\"\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    df_to_fasta(deduplicated_df, output_dir / f\"{input_path.stem}.fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sequence_header\": \"header\",\n",
      "    \"sequence_aa\": \"EVQVVSGGGVVQPGRSLRLSCTASGFTFSNFAMGWVRQAPGKGLEWVAFISSDGSNKNYGDSVKGRFTISRDNSKNTVFLQMNSLRVEDTALYYYCAKDVGGAFDLWGQGTYMVTVSP\",\n",
      "    \"numbering_scheme\": \"imgt\",\n",
      "    \"locus\": \"igh\",\n",
      "    \"stop_codon\": false,\n",
      "    \"productive\": true,\n",
      "    \"complete_vdj\": true,\n",
      "    \"v_call\": \"IGHV0-D4D7*00\",\n",
      "    \"j_call\": \"IGHJ0-TXGH*00\",\n",
      "    \"germline_alignment_aa\": \"EVQLVESGGGLVKPGGSLKLSCAASGFTFSDYGMHWVRQAPEKGLEWVAYISSGSSTIYYADTVKGRFTISRDNAKNTLFLQMTSLRSEDTAMYYCARNNNNNNAMDYWGQGTSVTVS\",\n",
      "    \"sequence_alignment_aa\": \"EVQVVSGGGVVQPGRSLRLSCTASGFTFSNFAMGWVRQAPGKGLEWVAFISSDGSNKNYGDSVKGRFTISRDNSKNTVFLQMNSLRVEDTALYYYCAKDVGGAFDLWGQGTYMVTVSP\",\n",
      "    \"v_alignment_start_aa\": 1,\n",
      "    \"v_alignment_end_aa\": 98,\n",
      "    \"j_alignment_start_aa\": 103,\n",
      "    \"j_alignment_end_aa\": 117,\n",
      "    \"v_sequence_alignment_aa\": \"EVQVVSGGGVVQPGRSLRLSCTASGFTFSNFAMGWVRQAPGKGLEWVAFISSDGSNKNYGDSVKGRFTISRDNSKNTVFLQMNSLRVEDTALYYYCAK\",\n",
      "    \"v_germline_alignment_aa\": \"EVQLVESGGGLVKPGGSLKLSCAASGFTFSDYGMHWVRQAPEKGLEWVAYISSGSSTIYYADTVKGRFTISRDNAKNTLFLQMTSLRSEDTAMYYCAR\",\n",
      "    \"j_sequence_alignment_aa\": \"AFDLWGQGTYMVTVS\",\n",
      "    \"j_germline_alignment_aa\": \"AMDYWGQGTSVTVS\",\n",
      "    \"fwr1_aa\": \"EVQVVSGGGVVQPGRSLRLSCTAS\",\n",
      "    \"cdr1_aa\": \"GFTFSNFA\",\n",
      "    \"fwr2_aa\": \"MGWVRQAPGKGLEWVAF\",\n",
      "    \"cdr2_aa\": \"ISSDGSNK\",\n",
      "    \"fwr3_aa\": \"NYGDSVKGRFTISRDNSKNTVFLQMNSLRVEDTALYYYC\",\n",
      "    \"cdr3_aa\": \"AKDVGGAFDL\",\n",
      "    \"fwr4_aa\": \"WGQGTYMVTVSP\",\n",
      "    \"junction_aa\": \"CAKDVGGAFDLW\",\n",
      "    \"junction_aa_length\": 12,\n",
      "    \"v_score_aa\": 142.30705651146974,\n",
      "    \"j_score_aa\": 22.470571536838868,\n",
      "    \"v_cigar_aa\": \"5M1D87M1I5M\",\n",
      "    \"j_cigar_aa\": \"9M1I5M\",\n",
      "    \"v_support_aa\": 4.806585191513681e-103,\n",
      "    \"j_support_aa\": 9.094947017729282e-12,\n",
      "    \"v_identity_aa\": 0.7272727272727273,\n",
      "    \"j_identity_aa\": 0.7333333333333333,\n",
      "    \"v_sequence_start_aa\": 1,\n",
      "    \"v_sequence_end_aa\": 98,\n",
      "    \"j_sequence_start_aa\": 103,\n",
      "    \"j_sequence_end_aa\": 117,\n",
      "    \"v_germline_start_aa\": 1,\n",
      "    \"v_germline_end_aa\": 98,\n",
      "    \"j_germline_start_aa\": 3,\n",
      "    \"j_germline_end_aa\": 16,\n",
      "    \"fwr1_start_aa\": 1,\n",
      "    \"fwr1_end_aa\": 24,\n",
      "    \"cdr1_start_aa\": 25,\n",
      "    \"cdr1_end_aa\": 32,\n",
      "    \"fwr2_start_aa\": 33,\n",
      "    \"fwr2_end_aa\": 49,\n",
      "    \"cdr2_start_aa\": 50,\n",
      "    \"cdr2_end_aa\": 57,\n",
      "    \"fwr3_start_aa\": 58,\n",
      "    \"fwr3_end_aa\": 96,\n",
      "    \"cdr3_start_aa\": 97,\n",
      "    \"cdr3_end_aa\": 106,\n",
      "    \"fwr4_start_aa\": 107,\n",
      "    \"fwr4_end_aa\": 118,\n",
      "    \"sequence_aa_scheme_cigar\": \"5M1D3M1D20M4D25M2D11M1D28M1I8M3D10M1I6M\",\n",
      "    \"scheme_residue_mapping\": {\n",
      "        \"1\": \"E\",\n",
      "        \"2\": \"V\",\n",
      "        \"3\": \"Q\",\n",
      "        \"4\": \"V\",\n",
      "        \"5\": \"V\",\n",
      "        \"7\": \"S\",\n",
      "        \"8\": \"G\",\n",
      "        \"9\": \"G\",\n",
      "        \"11\": \"G\",\n",
      "        \"12\": \"V\",\n",
      "        \"13\": \"V\",\n",
      "        \"14\": \"Q\",\n",
      "        \"15\": \"P\",\n",
      "        \"16\": \"G\",\n",
      "        \"17\": \"R\",\n",
      "        \"18\": \"S\",\n",
      "        \"19\": \"L\",\n",
      "        \"20\": \"R\",\n",
      "        \"21\": \"L\",\n",
      "        \"22\": \"S\",\n",
      "        \"23\": \"C\",\n",
      "        \"24\": \"T\",\n",
      "        \"25\": \"A\",\n",
      "        \"26\": \"S\",\n",
      "        \"27\": \"G\",\n",
      "        \"28\": \"F\",\n",
      "        \"29\": \"T\",\n",
      "        \"30\": \"F\",\n",
      "        \"35\": \"S\",\n",
      "        \"36\": \"N\",\n",
      "        \"37\": \"F\",\n",
      "        \"38\": \"A\",\n",
      "        \"39\": \"M\",\n",
      "        \"40\": \"G\",\n",
      "        \"41\": \"W\",\n",
      "        \"42\": \"V\",\n",
      "        \"43\": \"R\",\n",
      "        \"44\": \"Q\",\n",
      "        \"45\": \"A\",\n",
      "        \"46\": \"P\",\n",
      "        \"47\": \"G\",\n",
      "        \"48\": \"K\",\n",
      "        \"49\": \"G\",\n",
      "        \"50\": \"L\",\n",
      "        \"51\": \"E\",\n",
      "        \"52\": \"W\",\n",
      "        \"53\": \"V\",\n",
      "        \"54\": \"A\",\n",
      "        \"55\": \"F\",\n",
      "        \"56\": \"I\",\n",
      "        \"57\": \"S\",\n",
      "        \"58\": \"S\",\n",
      "        \"59\": \"D\",\n",
      "        \"62\": \"G\",\n",
      "        \"63\": \"S\",\n",
      "        \"64\": \"N\",\n",
      "        \"65\": \"K\",\n",
      "        \"66\": \"N\",\n",
      "        \"67\": \"Y\",\n",
      "        \"68\": \"G\",\n",
      "        \"69\": \"D\",\n",
      "        \"70\": \"S\",\n",
      "        \"71\": \"V\",\n",
      "        \"72\": \"K\",\n",
      "        \"74\": \"G\",\n",
      "        \"75\": \"R\",\n",
      "        \"76\": \"F\",\n",
      "        \"77\": \"T\",\n",
      "        \"78\": \"I\",\n",
      "        \"79\": \"S\",\n",
      "        \"80\": \"R\",\n",
      "        \"81\": \"D\",\n",
      "        \"82\": \"N\",\n",
      "        \"83\": \"S\",\n",
      "        \"84\": \"K\",\n",
      "        \"85\": \"N\",\n",
      "        \"86\": \"T\",\n",
      "        \"87\": \"V\",\n",
      "        \"88\": \"F\",\n",
      "        \"89\": \"L\",\n",
      "        \"90\": \"Q\",\n",
      "        \"91\": \"M\",\n",
      "        \"92\": \"N\",\n",
      "        \"93\": \"S\",\n",
      "        \"94\": \"L\",\n",
      "        \"95\": \"R\",\n",
      "        \"96\": \"V\",\n",
      "        \"97\": \"E\",\n",
      "        \"98\": \"D\",\n",
      "        \"99\": \"T\",\n",
      "        \"100\": \"A\",\n",
      "        \"101\": \"L\",\n",
      "        \"101.1\": \"Y\",\n",
      "        \"102\": \"Y\",\n",
      "        \"103\": \"Y\",\n",
      "        \"104\": \"C\",\n",
      "        \"105\": \"A\",\n",
      "        \"106\": \"K\",\n",
      "        \"107\": \"D\",\n",
      "        \"108\": \"V\",\n",
      "        \"109\": \"G\",\n",
      "        \"113\": \"G\",\n",
      "        \"114\": \"A\",\n",
      "        \"115\": \"F\",\n",
      "        \"116\": \"D\",\n",
      "        \"117\": \"L\",\n",
      "        \"118\": \"W\",\n",
      "        \"119\": \"G\",\n",
      "        \"120\": \"Q\",\n",
      "        \"121\": \"G\",\n",
      "        \"122\": \"T\",\n",
      "        \"122.1\": \"Y\",\n",
      "        \"123\": \"M\",\n",
      "        \"124\": \"V\",\n",
      "        \"125\": \"T\",\n",
      "        \"126\": \"V\",\n",
      "        \"127\": \"S\",\n",
      "        \"128\": \"P\"\n",
      "    },\n",
      "    \"positional_scheme_mapping\": {\n",
      "        \"0\": \"1\",\n",
      "        \"1\": \"2\",\n",
      "        \"2\": \"3\",\n",
      "        \"3\": \"4\",\n",
      "        \"4\": \"5\",\n",
      "        \"5\": \"7\",\n",
      "        \"6\": \"8\",\n",
      "        \"7\": \"9\",\n",
      "        \"8\": \"11\",\n",
      "        \"9\": \"12\",\n",
      "        \"10\": \"13\",\n",
      "        \"11\": \"14\",\n",
      "        \"12\": \"15\",\n",
      "        \"13\": \"16\",\n",
      "        \"14\": \"17\",\n",
      "        \"15\": \"18\",\n",
      "        \"16\": \"19\",\n",
      "        \"17\": \"20\",\n",
      "        \"18\": \"21\",\n",
      "        \"19\": \"22\",\n",
      "        \"20\": \"23\",\n",
      "        \"21\": \"24\",\n",
      "        \"22\": \"25\",\n",
      "        \"23\": \"26\",\n",
      "        \"24\": \"27\",\n",
      "        \"25\": \"28\",\n",
      "        \"26\": \"29\",\n",
      "        \"27\": \"30\",\n",
      "        \"28\": \"35\",\n",
      "        \"29\": \"36\",\n",
      "        \"30\": \"37\",\n",
      "        \"31\": \"38\",\n",
      "        \"32\": \"39\",\n",
      "        \"33\": \"40\",\n",
      "        \"34\": \"41\",\n",
      "        \"35\": \"42\",\n",
      "        \"36\": \"43\",\n",
      "        \"37\": \"44\",\n",
      "        \"38\": \"45\",\n",
      "        \"39\": \"46\",\n",
      "        \"40\": \"47\",\n",
      "        \"41\": \"48\",\n",
      "        \"42\": \"49\",\n",
      "        \"43\": \"50\",\n",
      "        \"44\": \"51\",\n",
      "        \"45\": \"52\",\n",
      "        \"46\": \"53\",\n",
      "        \"47\": \"54\",\n",
      "        \"48\": \"55\",\n",
      "        \"49\": \"56\",\n",
      "        \"50\": \"57\",\n",
      "        \"51\": \"58\",\n",
      "        \"52\": \"59\",\n",
      "        \"53\": \"62\",\n",
      "        \"54\": \"63\",\n",
      "        \"55\": \"64\",\n",
      "        \"56\": \"65\",\n",
      "        \"57\": \"66\",\n",
      "        \"58\": \"67\",\n",
      "        \"59\": \"68\",\n",
      "        \"60\": \"69\",\n",
      "        \"61\": \"70\",\n",
      "        \"62\": \"71\",\n",
      "        \"63\": \"72\",\n",
      "        \"64\": \"74\",\n",
      "        \"65\": \"75\",\n",
      "        \"66\": \"76\",\n",
      "        \"67\": \"77\",\n",
      "        \"68\": \"78\",\n",
      "        \"69\": \"79\",\n",
      "        \"70\": \"80\",\n",
      "        \"71\": \"81\",\n",
      "        \"72\": \"82\",\n",
      "        \"73\": \"83\",\n",
      "        \"74\": \"84\",\n",
      "        \"75\": \"85\",\n",
      "        \"76\": \"86\",\n",
      "        \"77\": \"87\",\n",
      "        \"78\": \"88\",\n",
      "        \"79\": \"89\",\n",
      "        \"80\": \"90\",\n",
      "        \"81\": \"91\",\n",
      "        \"82\": \"92\",\n",
      "        \"83\": \"93\",\n",
      "        \"84\": \"94\",\n",
      "        \"85\": \"95\",\n",
      "        \"86\": \"96\",\n",
      "        \"87\": \"97\",\n",
      "        \"88\": \"98\",\n",
      "        \"89\": \"99\",\n",
      "        \"90\": \"100\",\n",
      "        \"91\": \"101\",\n",
      "        \"92\": \"101.1\",\n",
      "        \"93\": \"102\",\n",
      "        \"94\": \"103\",\n",
      "        \"95\": \"104\",\n",
      "        \"96\": \"105\",\n",
      "        \"97\": \"106\",\n",
      "        \"98\": \"107\",\n",
      "        \"99\": \"108\",\n",
      "        \"100\": \"109\",\n",
      "        \"101\": \"113\",\n",
      "        \"102\": \"114\",\n",
      "        \"103\": \"115\",\n",
      "        \"104\": \"116\",\n",
      "        \"105\": \"117\",\n",
      "        \"106\": \"118\",\n",
      "        \"107\": \"119\",\n",
      "        \"108\": \"120\",\n",
      "        \"109\": \"121\",\n",
      "        \"110\": \"122\",\n",
      "        \"111\": \"122.1\",\n",
      "        \"112\": \"123\",\n",
      "        \"113\": \"124\",\n",
      "        \"114\": \"125\",\n",
      "        \"115\": \"126\",\n",
      "        \"116\": \"127\",\n",
      "        \"117\": \"128\"\n",
      "    },\n",
      "    \"exc\": null,\n",
      "    \"additional_validation_flags\": {\n",
      "        \"regions_aa_in_aligned_sequence_aa\": true,\n",
      "        \"cdr3_aa_in_junction_aa\": true,\n",
      "        \"locus_as_in_v_gene\": true,\n",
      "        \"v_gene_alignment_aa\": true,\n",
      "        \"j_gene_alignment_aa\": true,\n",
      "        \"no_negative_offsets_inside_v_alignment_aa\": true,\n",
      "        \"no_negative_offsets_inside_j_alignment_aa\": true,\n",
      "        \"consecutive_offsets_aa\": true,\n",
      "        \"no_empty_cdr3_aa\": true,\n",
      "        \"primary_sequence_in_sequence_alignment_aa\": true,\n",
      "        \"no_insertion_next_to_deletion_aa\": true,\n",
      "        \"insertions_in_correct_places\": false,\n",
      "        \"correct_fwr1_aa_offsets\": true,\n",
      "        \"correct_cdr1_aa_offsets\": true,\n",
      "        \"correct_fwr2_aa_offsets\": true,\n",
      "        \"correct_cdr2_aa_offsets\": true,\n",
      "        \"correct_fwr3_aa_offsets\": true,\n",
      "        \"correct_cdr3_aa_offsets\": true,\n",
      "        \"correct_fwr4_aa_offsets\": true,\n",
      "        \"no_empty_fwr1_aa_in_v\": true,\n",
      "        \"no_empty_cdr1_aa_in_v\": true,\n",
      "        \"no_empty_fwr2_aa_in_v\": true,\n",
      "        \"no_empty_cdr2_aa_in_v\": true,\n",
      "        \"no_empty_fwr3_aa_in_v\": true,\n",
      "        \"no_empty_fwr4_aa_in_j\": true,\n",
      "        \"conserved_C23_present\": true,\n",
      "        \"conserved_W41_present\": true,\n",
      "        \"conserved_C104_present\": true,\n",
      "        \"conserved_W118_heavy_present\": true\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# api use: /home/pawel/workspace/riot_na/notebooks/data_processing/data/gene_db/\n",
    "\n",
    "from dataclasses import asdict\n",
    "from riot_na.schemes.scheme_alignment import SchemeAligner\n",
    "from riot_na.alignment.aa_gene_alignments import create_vj_aligner_aa\n",
    "from riot_na.api.riot_numbering import RiotNumberingAA\n",
    "from pathlib import Path\n",
    "\n",
    "from riot_na.data.model import Organism, Scheme\n",
    "import json\n",
    "\n",
    "\n",
    "custom_db_dir = Path(\"/home/pawel/workspace/riot_na/notebooks/data_processing/data/\")\n",
    "\n",
    "scheme_alnr = SchemeAligner(db_dir=custom_db_dir, allowed_species=[Organism.CUSTOM])\n",
    "\n",
    "vdj_aa_alnr = create_vj_aligner_aa(allowed_species=[Organism.CUSTOM], db_dir=custom_db_dir)\n",
    "aa_numbering = RiotNumberingAA(vdj_aa_alnr, scheme_alnr)\n",
    "\n",
    "AA_QUERY = \"EVQVVSGGGVVQPGRSLRLSCTASGFTFSNFAMGWVRQAPGKGLEWVAFISSDGSNKNYGDSVKGRFTISRDNSKNTVFLQMNSLRVEDTALYYYCAKDVGGAFDLWGQGTYMVTVSP\"\n",
    "\n",
    "aa_sample_result = aa_numbering.run_on_sequence(\"header\", AA_QUERY, Scheme.IMGT)\n",
    "print(json.dumps(asdict(aa_sample_result), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# translate nt sequences to amino acids and split to the following structure\n",
    "# gene_db/aa_genes/v_genes/organism.fasta\n",
    "# gene_db/aa_genes/j_genes/organism/igh.fasta\n",
    "# gene_db/aa_genes/j_genes/organism/igk.fasta\n",
    "# gene_db/aa_genes/j_genes/organism/igl.fasta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for aa alignments we need to deduplicate the sequences (since aa sequences might be the same, we are unable to determine which gene is the correct one - so we dediplicate the sequences so we do not choke the prefiltering)\n",
    "# gene_db/aa_genes_deduplicated/v_genes/organism.fasta\n",
    "# gene_db/aa_genes_deduplicated/j_genes/organism/igh.fasta\n",
    "# gene_db/aa_genes_deduplicated/j_genes/organism/igk.fasta\n",
    "# gene_db/aa_genes_deduplicated/j_genes/organism/igl.fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nt v alleles: >IGHV4-28*07\tIGH\t0\tHOMO_SAPIENS\n",
    "# nt d alleles: >IGHD2-2*02\tHOMO_SAPIENS\n",
    "# nt j alleles: >IGHJ3*02\tIGH\t1\tHOMO_SAPIENS\n",
    "\n",
    "# aa v alleles: >IGHV1-45*03\tIGH\tHOMO_SAPIENS\n",
    "# aa j alleles: >IGHJ6*03\tIGH\tHOMO_SAPIENS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automation-EZMDX5Qf-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
